{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Econometrics: Group Assignment 1\n",
    "\n",
    "## Students of Group 5\n",
    "\n",
    "Yi-Pei Siao, 2872991, y.p.siao@student.vu.nl;\n",
    "Sofia Jeong, 2894452, e.jeong@student.vu.nl;\n",
    "Avril Rodriguez, 2903029, a.v.rodriguez@student.vu.nl;\n",
    "Pepijn Bouwman, 2892824, p.bouwman2@student.vu.nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4RVkaxWJnOM",
    "outputId": "2852c687-398d-4ac1-b4f4-9ef01b99e2c6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import math\n",
    "import warnings\n",
    "# !pip install numdifftools\n",
    "import numdifftools as nd\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import t as student_t\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- I/O settings ---\n",
    "DATA_FILE = \"crsp_data.csv\"\n",
    "OUT_DIR = \"outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWFHL2bT9MtG"
   },
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "V1wTb5GTKJ2t",
    "outputId": "cf9d3218-94a2-4696-a63b-925a8d467302"
   },
   "outputs": [],
   "source": [
    "# --- Question 2 ---\n",
    "\n",
    "# Given parameters and initialization\n",
    "alpha = 0.4\n",
    "gamma = [0.01, 0.1, 1.0]\n",
    "delta = [0.3, 0.1, 0.0, -0.3]\n",
    "\n",
    "x = np.linspace(-5, 5,1000) # X-axis\n",
    "# x = np.linspace(-125, 125,1000) not visible\n",
    "\n",
    "lines = ['-', '--', ':']\n",
    "\n",
    "# News Impact Curve definition followed by the given parameter setting as default\n",
    "def nic(x, delta, gamma, mu = 0, lam = 0, sig2_init = 1, omega = 0, beta = 0):\n",
    "    NIC = omega + (alpha + delta * np.tanh(-gamma * x)) * ((x-mu-lam*sig2_init)**2/(sig2_init)) + beta * sig2_init\n",
    "    return NIC\n",
    "\n",
    "# Ploting\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for ax, d in zip(axes, delta):\n",
    "    for g, style in zip(gamma, lines):\n",
    "        news_impact = nic(x, d, g)\n",
    "        ax.plot(x, news_impact, linestyle=style, label=fr\"$\\gamma={g}$\")\n",
    "    ax.axvline(0, lw=0.3, alpha=0.7, color='grey')\n",
    "    ax.set_xticks(np.linspace(-5, 5, 5))\n",
    "    ax.set_title(fr\"News impact curves with $\\delta={d}$\")\n",
    "    ax.set_xlabel(r\"$x_{t-1}$\")\n",
    "    ax.set_ylabel(\"News impact, $\\sigma^2_{t}$\")\n",
    "    ax.legend(frameon=True, fontsize=9)\n",
    "\n",
    "# fig.suptitle(r\"News impact curves for the GARCH-M-L model $(\\mu=0$, $\\lambda=0$, $\\alpha=0.4$, $\\sigma^2_{t-1}=1)$\", fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(OUT_DIR, \"Q2_NIC_plots.png\"), dpi=400, bbox_inches=\"tight\")\n",
    "fig.savefig(os.path.join(OUT_DIR, \"Q2_NIC_plots.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SlMm4sg9QBm"
   },
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "wUAcFOm9KLsI",
    "outputId": "e979ae34-f0ab-40db-c88a-81b581773f98"
   },
   "outputs": [],
   "source": [
    "# --- Question 3 ---\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Scale returns IN MEMORY (do NOT overwrite CSV on disk)\n",
    "df[\"RET\"] = df[\"RET\"] * 100\n",
    "\n",
    "# Descriptive statistics per ticker\n",
    "def describe_series(x: pd.Series) -> dict:\n",
    "    x = x.dropna()\n",
    "    return {\n",
    "        \"N\": int(x.shape[0]),\n",
    "        \"Mean\": x.mean(),\n",
    "        \"Median\": x.median(),\n",
    "        \"Std. Dev.\": x.std(ddof=1),\n",
    "        \"Skewness\": x.skew(),\n",
    "        \"Excess Kurtosis\": x.kurt(),  # pandas: Fisher definition -> excess kurtosis\n",
    "        \"Min\": x.min(),\n",
    "        \"Max\": x.max(),\n",
    "    }\n",
    "\n",
    "stats_rows = []\n",
    "for tkr, g in df.groupby(\"TICKER\", sort=True):\n",
    "    stats_rows.append(pd.Series(describe_series(g[\"RET\"]), name=tkr))\n",
    "\n",
    "stats_df = pd.DataFrame(stats_rows)\n",
    "stats_df = stats_df[[\"N\",\"Mean\",\"Median\",\"Std. Dev.\",\"Skewness\",\"Excess Kurtosis\",\"Min\",\"Max\"]]\n",
    "\n",
    "# Rounded copy for reporting\n",
    "stats_rounded = stats_df.copy()\n",
    "stats_rounded[[\"Mean\",\"Median\",\"Std. Dev.\",\"Skewness\",\"Excess Kurtosis\",\"Min\",\"Max\"]] = \\\n",
    "    stats_rounded[[\"Mean\",\"Median\",\"Std. Dev.\",\"Skewness\",\"Excess Kurtosis\",\"Min\",\"Max\"]].round(4)\n",
    "\n",
    "# Save outputs\n",
    "stats_rounded.to_csv(os.path.join(OUT_DIR, \"Q3_d_stats.csv\"))\n",
    "with open(os.path.join(OUT_DIR, \"Q3_d_stats.tex\"), \"w\") as f:\n",
    "    f.write(\n",
    "        stats_rounded.to_latex(\n",
    "            caption=\"Descriptive statistics of daily holding period returns (in %).\",\n",
    "            label=\"tab:Q3_desc_stats\",\n",
    "            index=True,\n",
    "            escape=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\"Saved:\", os.path.join(OUT_DIR, \"Q3_d_stats.csv\"))\n",
    "print(\"Saved:\", os.path.join(OUT_DIR, \"Q3_d_stats.tex\"))\n",
    "\n",
    "# Check Apple values\n",
    "check = stats_df.loc[\"AAPL\", [\"Mean\", \"Std. Dev.\", \"Min\", \"Max\"]].round(4)\n",
    "print(\"\\nAAPL check (Mean, Std. Dev., Min, Max):\")\n",
    "print(check.to_string())\n",
    "\n",
    "\n",
    "# Plots on 2x2 panel\n",
    "tickers = [\"AAPL\", \"JNJ\", \"MRK\", \"PFE\"]\n",
    "df_plot = df.dropna(subset=[\"date\", \"RET\"]).copy()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7), sharex=False, sharey=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(tickers) and tickers[i] in df_plot[\"TICKER\"].unique():\n",
    "        tkr = tickers[i]\n",
    "        sub = df_plot[df_plot[\"TICKER\"] == tkr].sort_values(\"date\")\n",
    "        ax.plot(sub[\"date\"], sub[\"RET\"], linewidth=0.9, label=f\"{tkr} daily return\")\n",
    "        ax.axhline(0, linewidth=0.8, color=\"black\")\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.set_title(tkr)\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(\"Daily return (%)\")\n",
    "        ax.xaxis.set_major_locator(mdates.YearLocator(base=2))  # tick every 2 years\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "        ax.legend(loc=\"upper left\", frameon=False, fontsize=8)\n",
    "    else:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Daily Holding Period Returns by Stock (in %)\", y=0.98)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(OUT_DIR, \"Q3_returns_plots.png\"), dpi=200, bbox_inches=\"tight\")\n",
    "fig.savefig(os.path.join(OUT_DIR, \"Q3_returns_plots.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GfUE2_7FNsl"
   },
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGG47od0FDHx"
   },
   "outputs": [],
   "source": [
    "# Define negative log-likelihood functions for each GARCH model\n",
    "\n",
    "def neg_logL_GARCH(params, x):\n",
    "    mu, omega, alpha, beta, nu = params\n",
    "    T = x.size\n",
    "\n",
    "    if alpha < 0 or omega <= 0 or beta < 0 or nu <= 2.001:\n",
    "        return 1e12\n",
    "\n",
    "    # if alpha + beta >= 0.9999:\n",
    "    #     return 1e10 + 1e8 * (alpha + beta - 0.9999)\n",
    "\n",
    "    sigma_sqrd = np.zeros(T)\n",
    "    sigma_sqrd[0] = np.average((x[:50] - np.average(x[:50]))**2)\n",
    "\n",
    "    for t in range(1, T):\n",
    "        resid_prev = (x[t-1] - mu) / np.sqrt(np.maximum(sigma_sqrd[t-1], 1e-12))\n",
    "        sigma_sqrd[t] = omega + alpha * resid_prev**2 + beta * sigma_sqrd[t-1]\n",
    "\n",
    "        if not np.isfinite(sigma_sqrd[t]) or sigma_sqrd[t] <= 0:\n",
    "            return 1e12\n",
    "\n",
    "    epsilon = (x - mu) / np.sqrt(sigma_sqrd)\n",
    "\n",
    "    log_pdf = (\n",
    "        math.lgamma((nu + 1) / 2)\n",
    "        - 0.5 * np.log(nu * np.pi)\n",
    "        - math.lgamma(nu / 2)\n",
    "        - ((nu + 1) / 2) * np.log(1 + epsilon**2 / nu)\n",
    "    )\n",
    "\n",
    "    logL = np.sum(log_pdf - 0.5 * np.log(sigma_sqrd))\n",
    "    return -logL\n",
    "\n",
    "def neg_logL_GARCH_M(params, x):\n",
    "    mu, lam, omega, alpha, beta, nu = params\n",
    "    T = x.size\n",
    "\n",
    "    if alpha < 0 or omega <= 0 or beta < 0 or nu <= 2.001:\n",
    "        return 1e12\n",
    "\n",
    "    # if alpha + beta >= 0.9999:\n",
    "    #     return 1e10 + 1e8 * (alpha + beta - 0.9999)\n",
    "\n",
    "    sigma_sqrd = np.zeros(T)\n",
    "    sigma_sqrd[0] = np.average((x[:50] - np.average(x[:50]))**2)\n",
    "\n",
    "    for t in range(1, T):\n",
    "        cond_mean = mu + lam * sigma_sqrd[t-1]\n",
    "        resid_prev = (x[t-1] - cond_mean) / np.sqrt(np.maximum(sigma_sqrd[t-1], 1e-12))\n",
    "        sigma_sqrd[t] = omega + alpha * resid_prev**2 + beta * sigma_sqrd[t-1]\n",
    "\n",
    "        if not np.isfinite(sigma_sqrd[t]) or sigma_sqrd[t] <= 0:\n",
    "            return 1e12\n",
    "\n",
    "    epsilon = (x - (mu + lam * sigma_sqrd)) / np.sqrt(sigma_sqrd)\n",
    "\n",
    "    log_pdf = (\n",
    "        math.lgamma((nu + 1) / 2)\n",
    "        - 0.5 * np.log(nu * np.pi)\n",
    "        - math.lgamma(nu / 2)\n",
    "        - ((nu + 1) / 2) * np.log(1 + epsilon**2 / nu)\n",
    "    )\n",
    "\n",
    "    logL = np.sum(log_pdf - 0.5 * np.log(sigma_sqrd))\n",
    "    return -logL\n",
    "\n",
    "def neg_logL_GARCH_M_L(params, x):\n",
    "    mu, lam, omega, alpha, delta, gamma, beta, nu = params\n",
    "    T = x.size\n",
    "\n",
    "    if alpha < 0 or omega <= 0 or beta < 0 or nu <= 2.001 or gamma <= 0:\n",
    "        return 1e12\n",
    "\n",
    "    # if alpha + beta >= 0.9999:\n",
    "    #     return 1e10 + 1e8 * (alpha + beta - 0.9999)\n",
    "\n",
    "    if alpha <= abs(delta):\n",
    "        return 1e10 + 1e8 * (abs(delta) - alpha)\n",
    "\n",
    "    sigma_sqrd = np.zeros(T)\n",
    "    sigma_sqrd[0] = np.average((x[:50] - np.average(x[:50]))**2)\n",
    "\n",
    "    for t in range(1, T):\n",
    "        cond_mean = mu + lam * sigma_sqrd[t-1]\n",
    "        resid_prev = (x[t-1] - cond_mean) / np.sqrt(np.maximum(sigma_sqrd[t-1], 1e-6))\n",
    "        arch_coeff = alpha + delta * np.tanh(-gamma * x[t-1])\n",
    "        sigma_sqrd[t] = omega + arch_coeff * resid_prev**2 + beta * sigma_sqrd[t-1]\n",
    "\n",
    "        if not np.isfinite(sigma_sqrd[t]) or sigma_sqrd[t] <= 0:\n",
    "            return 1e12\n",
    "\n",
    "    epsilon = (x - (mu + lam * sigma_sqrd)) / np.sqrt(sigma_sqrd)\n",
    "\n",
    "    log_pdf = (\n",
    "        math.lgamma((nu + 1) / 2)\n",
    "        - 0.5 * np.log(nu * np.pi)\n",
    "        - math.lgamma(nu / 2)\n",
    "        - ((nu + 1) / 2) * np.log(1 + epsilon**2 / nu)\n",
    "    )\n",
    "\n",
    "    logL = np.sum(log_pdf - 0.5 * np.log(sigma_sqrd))\n",
    "    return -logL + 0.001 * gamma**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8Bzo7f6q_ph",
    "outputId": "a267fa6d-f02d-46fd-c80c-5a2da730ba34"
   },
   "outputs": [],
   "source": [
    "# Check if log-likelihood is correct w/ givenn optimal parameters\n",
    "\n",
    "test_params_GARCH = [\n",
    "    0.154 ,    # mu\n",
    "    0.038,     # omega\n",
    "    0.090,     # alpha\n",
    "    0.873,     # beta\n",
    "    4.146      # nu\n",
    "]\n",
    "\n",
    "test_params_GARCH_M = [\n",
    "    0.072,     # mu\n",
    "    0.061,     # lam\n",
    "    0.037,     # omega\n",
    "    0.089,     # alpha\n",
    "    0.875,     # beta\n",
    "    4.138      # nu\n",
    "]\n",
    "\n",
    "test_params_GARCH_M_L = [\n",
    "    0.108,     # mu\n",
    "    0.022,     # lam\n",
    "    0.012,     # omega\n",
    "    0.073,     # alpha\n",
    "    0.071,     # delta\n",
    "    0.439,     # gamma\n",
    "    0.915,     # beta\n",
    "    4.402      # nu\n",
    "]\n",
    "\n",
    "# Get your data\n",
    "ret_AAPL = df[df['TICKER'] == 'AAPL']['RET'].iloc[:2500]\n",
    "\n",
    "# Calculate the negative log-likelihood for each parameter set\n",
    "nll_garch = neg_logL_GARCH(test_params_GARCH, ret_AAPL)\n",
    "nll_garch_m = neg_logL_GARCH_M(test_params_GARCH_M, ret_AAPL)\n",
    "nll_garch_m_l = neg_logL_GARCH_M_L(test_params_GARCH_M_L, ret_AAPL)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Log-Likelihood for GARCH: {-nll_garch:.0f}\") # Should be -4662\n",
    "print(\"---\")\n",
    "print(f\"Log-Likelihood for GARCH-M: {-nll_garch_m:.0f}\") # Should be -4662\n",
    "print(\"---\")\n",
    "print(f\"Log-Likelihood for GARCH-M-L: {-nll_garch_m_l:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1wDysZ8KdPp"
   },
   "outputs": [],
   "source": [
    "# Define functions to fit each GARCH model\n",
    "\n",
    "def fit_GARCH_model(returns, model_type, start_params, bounds):\n",
    "    x = np.asarray(returns, dtype=float)\n",
    "    T = x.size\n",
    "\n",
    "    if model_type == 'GARCH':\n",
    "        obj_func = neg_logL_GARCH\n",
    "    elif model_type == 'GARCH-M':\n",
    "        obj_func = neg_logL_GARCH_M\n",
    "    elif model_type == 'GARCH-M-L':\n",
    "        obj_func = neg_logL_GARCH_M_L\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type specified.\")\n",
    "\n",
    "    optim = minimize(lambda p: obj_func(p, x),\n",
    "                     x0=start_params,\n",
    "                     bounds=bounds,\n",
    "                     method='L-BFGS-B',\n",
    "                     options={'disp': False})\n",
    "\n",
    "    param_estimates = optim.x\n",
    "    H, cov, se = None, None, None\n",
    "    if nd:\n",
    "        try:\n",
    "            hess_func = nd.Hessian(lambda p: obj_func(p, x))\n",
    "            H = hess_func(param_estimates)\n",
    "            cov = np.linalg.pinv(H)\n",
    "            se = np.sqrt(np.maximum(np.diag(cov), 0.0))\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Hessian failed: {e}\")\n",
    "\n",
    "    # Re-calculate final sigma and standardized residuals using the estimated params\n",
    "    final_params = param_estimates\n",
    "    sigma_sqrd = np.zeros(T)\n",
    "    sigma_sqrd[0] = np.average((x[:50] - np.average(x[:50]))**2)\n",
    "\n",
    "    # Note: This block re-simulates the variance.\n",
    "    if model_type == 'GARCH':\n",
    "        mu, omega, alpha, beta, nu = final_params\n",
    "        cond_mean = mu\n",
    "        for t in range(1, T):\n",
    "            resid_prev = (x[t-1] - cond_mean) / np.sqrt(sigma_sqrd[t-1])\n",
    "            sigma_sqrd[t] = omega + alpha * resid_prev**2 + beta * sigma_sqrd[t-1]\n",
    "        epsilon = (x - cond_mean) / np.sqrt(sigma_sqrd)\n",
    "    elif model_type == 'GARCH-M':\n",
    "        mu, lam, omega, alpha, beta, nu = final_params\n",
    "        for t in range(1, T):\n",
    "            cond_mean = mu + lam * sigma_sqrd[t-1]\n",
    "            resid_prev = (x[t-1] - cond_mean) / np.sqrt(sigma_sqrd[t-1])\n",
    "            sigma_sqrd[t] = omega + alpha * resid_prev**2 + beta * sigma_sqrd[t-1]\n",
    "        epsilon = (x - (mu + lam * sigma_sqrd)) / np.sqrt(sigma_sqrd)\n",
    "    elif model_type == 'GARCH-M-L':\n",
    "        mu, lam, omega, alpha, delta, gamma, beta, nu = final_params\n",
    "        for t in range(1, T):\n",
    "            cond_mean = mu + lam * sigma_sqrd[t-1]\n",
    "            resid_prev = (x[t-1] - cond_mean) / np.sqrt(sigma_sqrd[t-1])\n",
    "            arch_coeff = alpha + delta * np.tanh(-gamma * x[t-1])\n",
    "            sigma_sqrd[t] = omega + arch_coeff * resid_prev**2 + beta * sigma_sqrd[t-1]\n",
    "        epsilon = (x - (mu + lam * sigma_sqrd)) / np.sqrt(sigma_sqrd)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type specified.\")\n",
    "\n",
    "    logL = -optim.fun\n",
    "    k = len(param_estimates)\n",
    "\n",
    "    result = {\n",
    "        'params': param_estimates,\n",
    "        'se': se,\n",
    "        'cov': cov,\n",
    "        'hess': H,\n",
    "        'nll': optim.fun,\n",
    "        'success': optim.success,\n",
    "        'message': optim.message,\n",
    "        'fitted_sigma2': sigma_sqrd,\n",
    "        'std_resid': epsilon,\n",
    "        'df': T,\n",
    "        'logL': logL,\n",
    "        'AIC': 2*k - 2*logL,\n",
    "        'BIC': k*np.log(T) - 2*logL\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nL5VFLJtHV0X"
   },
   "outputs": [],
   "source": [
    "def print_results(results_dict, model_type):\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(f\"RESULTS FOR THE {model_type.upper()} MODEL\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Check if the optimization was successful\n",
    "    if not results_dict['success']:\n",
    "        print(f\"Warning: Optimization failed. Message: {results_dict['message']}\\n\")\n",
    "\n",
    "    # Define parameter names based on the model type\n",
    "    if model_type == 'GARCH':\n",
    "        param_names = ['mu', 'omega', 'alpha', 'beta', 'nu']\n",
    "    elif model_type == 'GARCH-M':\n",
    "        param_names = ['mu', 'lam', 'omega', 'alpha', 'beta', 'nu']\n",
    "    elif model_type == 'GARCH-M-L':\n",
    "        param_names = ['mu', 'lam', 'omega', 'alpha', 'delta', 'gamma', 'beta', 'nu']\n",
    "    else:\n",
    "        param_names = [] # Fallback for unknown model types\n",
    "\n",
    "    # Create a table for parameters and standard errors\n",
    "    params = results_dict['params']\n",
    "    se = results_dict['se']\n",
    "\n",
    "    if se is not None and len(se) == len(params):\n",
    "        param_table = pd.DataFrame({\n",
    "            'Parameter': results_dict['params'],\n",
    "            'Standard Error': results_dict['se']\n",
    "        })\n",
    "        param_table.index = param_names\n",
    "        print(\"\\n-------Parameter  Estimates-------\")\n",
    "        print(param_table.to_string(float_format=\"%.3f\"))\n",
    "\n",
    "    else:\n",
    "        print(\"\\n-------Parameter  Estimates-------\")\n",
    "        for name, value in zip(param_names, params):\n",
    "            print(f\"  {name: <10}: {value: .3f}\")\n",
    "\n",
    "    print(\"\\n------Goodness of Fit Metrics------\")\n",
    "    print(f\"  Negative Log-Likelihood: {results_dict['nll']:.3f}\")\n",
    "    print(f\"  Log-Likelihood: {results_dict['logL']:.3f}\")\n",
    "    print(f\"  AIC (Akaike Information Criterion): {results_dict['AIC']:.3f}\")\n",
    "    print(f\"  BIC (Bayesian Information Criterion): {results_dict['BIC']:.3f}\")\n",
    "\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6Fws75Wgf3L"
   },
   "outputs": [],
   "source": [
    "# Define bounds for each model\n",
    "bounds_GARCH = [\n",
    "    (-2.0, 2.0),     # mu\n",
    "    (1e-6, None),    # omega\n",
    "    (1e-6, 0.95),    # alpha\n",
    "    (1e-6, 0.999),   # beta\n",
    "    (2.05, 50.0)     # nu\n",
    "]\n",
    "\n",
    "bounds_GARCH_M = [\n",
    "    (-2.0, 2.0),     # mu\n",
    "    (-0.2, 0.2),     # lambda\n",
    "    (1e-6, None),    # omega\n",
    "    (1e-6, 0.95),    # alpha\n",
    "    (1e-6, 0.999),   # beta\n",
    "    (2.05, 50.0)     # nu\n",
    "]\n",
    "\n",
    "bounds_GARCH_M_L = [\n",
    "    (-2.0, 2.0),     # mu\n",
    "    (-0.2, 0.2),     # lambda  (first pass)\n",
    "    (1e-6, None),    # omega\n",
    "    (1e-6, 0.95),    # alpha\n",
    "    (-1.0, 1.0),     # delta\n",
    "    (1e-6, 20.0),    # gamma   (20 already saturates over |x|<=5)\n",
    "    (1e-6, 0.999),   # beta\n",
    "    (2.05, 50.0)     # nu\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WdOV5jbsUto",
    "outputId": "7a8ac293-5b6a-4635-9780-2704501a9bfe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lists of tickers, model types, start parameters, and bounds\n",
    "\n",
    "tickers_to_fit = ['MRK', 'AAPL','PFE', 'JNJ' ]\n",
    "model_types = ['GARCH', 'GARCH-M', 'GARCH-M-L']\n",
    "bounds_list = [bounds_GARCH, bounds_GARCH_M, bounds_GARCH_M_L]\n",
    "\n",
    "results = {}\n",
    "par_results = {}\n",
    "# Loop over tickers and model type\n",
    "\n",
    "for ticker in tickers_to_fit:\n",
    "  print(\"=\" * 60)\n",
    "  print(f\"\\nFITTING MODELS FOR TICKER: {ticker}\\n\")\n",
    "  print(\"=\" * 60)\n",
    "\n",
    "  ret_per_ticker = df[df['TICKER'] == ticker]['RET'].iloc[:2500]\n",
    "  sample_var = np.var(ret_per_ticker)\n",
    "\n",
    "  start_param_GARCH = [\n",
    "      0,                 # mu\n",
    "      sample_var / 50,   # omega\n",
    "      0.05,              # alpha\n",
    "      0.9,               # beta\n",
    "      10                 # nu\n",
    "  ]\n",
    "\n",
    "  start_param_GARCH_M = [\n",
    "      0,                 # mu\n",
    "      0,                 # lambda\n",
    "      sample_var / 50,   # omega\n",
    "      0.05,              # alpha\n",
    "      0.9,               # beta\n",
    "      10                 # nu\n",
    "  ]\n",
    "\n",
    "  start_param_GARCH_M_L = [\n",
    "      0,                 # mu\n",
    "      0,                 # lambda\n",
    "      sample_var / 50,   # omega\n",
    "      0.05,              # alpha\n",
    "      0.01,              # delta\n",
    "      0.01,              # gamma\n",
    "      0.9,               # beta\n",
    "      10                 # nu\n",
    "  ]\n",
    "\n",
    "  model_fit_list = []\n",
    "  start_params_list = [start_param_GARCH, start_param_GARCH_M, start_param_GARCH_M_L]\n",
    "  par_results[ticker] = {}\n",
    "  for model_type, start_params, bounds in zip(model_types, start_params_list, bounds_list):\n",
    "      results = fit_GARCH_model(ret_per_ticker, model_type, start_params, bounds)\n",
    "      model_fit_list.append(results)\n",
    "      par_results[ticker][model_type] = results['params']\n",
    "      print_results(results, model_type)\n",
    "\n",
    "results[ticker] = model_fit_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Question 5 --- \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Load data\n",
    "DF = pd.read_csv(\"crsp_data.csv\")\n",
    "DF.columns = DF.columns.str.lower()\n",
    "DF[\"date\"] = pd.to_datetime(DF[\"date\"])\n",
    "DF = DF.sort_values([\"ticker\",\"date\"])\n",
    "\n",
    "# Residual Diagnostics Helper\n",
    "def ljung_box(resid, lags=20):\n",
    "    lb1 = acorr_ljungbox(resid, lags=lags, return_df=True)\n",
    "    lb2 = acorr_ljungbox(resid**2, lags=lags, return_df=True)\n",
    "    return (\n",
    "        lb1[\"lb_stat\"].iloc[-1], lb1[\"lb_pvalue\"].iloc[-1],\n",
    "        lb2[\"lb_stat\"].iloc[-1], lb2[\"lb_pvalue\"].iloc[-1]\n",
    "    )\n",
    "\n",
    "def arch_lm(resid, L=10):\n",
    "    z2 = resid**2\n",
    "    y = z2[L:]\n",
    "    X = np.column_stack([z2[L-i-1:-i-1] for i in range(L)])\n",
    "    X = np.column_stack([np.ones(len(X)), X])  \n",
    "    beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    yhat = X @ beta\n",
    "    ss_tot = ((y - y.mean())**2).sum()\n",
    "    ss_res = ((y - yhat)**2).sum()\n",
    "    R2 = 0.0 if ss_tot <= 0 else 1 - ss_res/ss_tot\n",
    "    T = len(y)\n",
    "    stat = T * R2\n",
    "    p = 1 - stats.chi2.cdf(stat, df=L)\n",
    "    return stat, p\n",
    "\n",
    "def jarque_bera(resid):\n",
    "    JB, p = stats.jarque_bera(resid)\n",
    "    return JB, p\n",
    "\n",
    "def persistence_half_life(alpha, beta):\n",
    "    phi = alpha + beta\n",
    "    hl = np.inf if (phi <= 0 or phi >= 1) else np.log(0.5)/np.log(phi)\n",
    "    return phi, hl\n",
    "\n",
    "# sigma_t^2 & Standardized Residuals ----------\n",
    "def build_sigma2_series(x, sigma1_sq, model, params):\n",
    "    \"\"\"\n",
    "    model: 'GARCH' | 'GARCH-M' | 'GARCH-M-L'\n",
    "    params keys:\n",
    "      mu, omega, alpha, beta, [lam], [delta], [gamma]\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    sigma2 = np.empty(n, dtype=float)\n",
    "    sigma2[0] = max(sigma1_sq, 1e-10)\n",
    "\n",
    "    mu    = float(params.get(\"mu\", 0.0))\n",
    "    lam   = float(params.get(\"lam\", 0.0))\n",
    "    omega = float(params[\"omega\"])\n",
    "    alpha = float(params[\"alpha\"])\n",
    "    beta  = float(params[\"beta\"])\n",
    "    delta = float(params.get(\"delta\", 0.0))\n",
    "    gamma = float(params.get(\"gamma\", 0.0))\n",
    "\n",
    "    for t in range(1, n):\n",
    "        lever = 0.0\n",
    "        if model == \"GARCH-M-L\":\n",
    "            lever = delta * x[t-1] + gamma * (1.0 if x[t-1] >= 0 else -1.0) * x[t-1]\n",
    "        sigma2[t] = omega + alpha*(x[t-1]**2) + beta*sigma2[t-1] + lever\n",
    "        if sigma2[t] <= 0:\n",
    "            sigma2[t] = 1e-10  \n",
    "\n",
    "    sigma = np.sqrt(sigma2)\n",
    "    z = (x - mu - lam*sigma2) / sigma\n",
    "    return sigma2, z\n",
    "\n",
    "# ---------- main ----------\n",
    "def run_q5_for_ticker(df, ticker, n_obs=2500, lb_lags=20, lm_lags=10,\n",
    "                      model=\"GARCH-M-L\", params=None,\n",
    "                      assume_params_in_percent=False): # False = percentage\n",
    "    x = df[df[\"ticker\"]==ticker][\"ret\"].dropna().values[:n_obs]\n",
    "\n",
    "    # initial: first 50 (/n）\n",
    "    init = x[:50]\n",
    "    sigma1_sq = ((init - init.mean())**2).mean()\n",
    "\n",
    "    if params is None:\n",
    "        raise ValueError(\"Need params（according to question 4）\")\n",
    "\n",
    "    p = params.copy()\n",
    "    if assume_params_in_percent:\n",
    "        for key in [\"mu\",\"lam\",\"delta\",\"gamma\"]:\n",
    "            if key in p:\n",
    "                p[key] = p[key] / 100.0\n",
    "\n",
    "    sigma2_hat, z = build_sigma2_series(x, sigma1_sq, model, p)\n",
    "\n",
    "    # test\n",
    "    Qz, pz, Qz2, pz2 = ljung_box(z, lags=lb_lags)\n",
    "    LM, pLM = arch_lm(z, L=lm_lags)\n",
    "    JB, pJB = jarque_bera(z)\n",
    "    phi, HL = persistence_half_life(p[\"alpha\"], p[\"beta\"])\n",
    "\n",
    "    out = {\n",
    "        \"Ticker\": ticker,\n",
    "        \"Model\": model,\n",
    "        \"LB(z)_stat\": Qz,   \"LB(z)_p\": pz,\n",
    "        \"LB(z2)_stat\": Qz2, \"LB(z2)_p\": pz2,\n",
    "        \"ARCH-LM_stat\": LM, \"ARCH-LM_p\": pLM,\n",
    "        \"JB_stat\": JB,      \"JB_p\": pJB,\n",
    "        \"alpha+beta\": phi,  \"Half-life_days\": HL\n",
    "    }\n",
    "    return out, sigma2_hat, z\n",
    "\n",
    "# ---------- The optimal model parameters from Q4 ----------\n",
    "BEST = {\n",
    "    \"PFE\":  {\"model\":\"GARCH-M-L\", \"params\":{\"mu\":-0.045, \"lam\":0.122, \"omega\":0.000, \"alpha\":0.044, \"beta\":0.920, \"delta\":0.027, \"gamma\":17.124}},\n",
    "    \"JNJ\":  {\"model\":\"GARCH-M-L\", \"params\":{\"mu\":0.033,  \"lam\":0.063, \"omega\":0.003, \"alpha\":0.026, \"beta\":0.916, \"delta\":0.017, \"gamma\":1.229}},\n",
    "    \"MRK\":  {\"model\":\"GARCH-M\",   \"params\":{\"mu\":0.077,  \"lam\":0.065, \"omega\":0.015, \"alpha\":0.040, \"beta\":0.904}},\n",
    "    \"AAPL\": {\"model\":\"GARCH-M-L\", \"params\":{\"mu\":0.096,  \"lam\":0.027, \"omega\":0.023, \"alpha\":0.069, \"beta\":0.911, \"delta\":0.061, \"gamma\":10.474}},\n",
    "}\n",
    "\n",
    "ASSUME_PCT = False\n",
    "\n",
    "# ---------- Batch run for four stocks, export results to CSV ----------\n",
    "rows = []\n",
    "STORE = {}  # # Store each stock’s (sigma², z) for Q6 plotting\n",
    "for tkr, spec in BEST.items():\n",
    "    out, s2, z = run_q5_for_ticker(\n",
    "        DF, tkr, n_obs=2500, lb_lags=20, lm_lags=10,\n",
    "        model=spec[\"model\"], params=spec[\"params\"],\n",
    "        assume_params_in_percent=ASSUME_PCT\n",
    "    )\n",
    "    rows.append(out)\n",
    "    STORE[tkr] = {\"sigma2\": s2, \"z\": z}\n",
    "\n",
    "diag_df = pd.DataFrame(rows)\n",
    "diag_df_rounded = diag_df.copy()\n",
    "num_cols = [c for c in diag_df.columns if c not in [\"Ticker\",\"Model\"]]\n",
    "diag_df_rounded[num_cols] = diag_df_rounded[num_cols].astype(float).round(4)\n",
    "print(diag_df_rounded)\n",
    "\n",
    "diag_df_rounded.to_csv(\"q5_diagnostics.csv\", index=False)\n",
    "print(\"Saved: q5_diagnostics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "RETURNS_CSV = \"crsp_data.csv\"\n",
    "\n",
    "# 2) In-sample cutoff (after the first 2,500 obs in the assignment).\n",
    "IN_SAMPLE_CUTOFF_DATE = \"2021-01-04\"\n",
    "\n",
    "# 3) Q4 parameter estimates\n",
    "#    Put None for irrelevant fields (e.g., lam for GARCH is 0; delta,gamma for models w/o leverage are 0).\n",
    "#    Stock tickers MUST be 'PFE','JNJ','MRK' (AAPL not required in Q5).\n",
    "PARAMS = {\n",
    "    \"PFE\": {\n",
    "        \"GARCH\":     dict(mu=0.059, lam=0.0,   omega=0.000, alpha=0.043, beta=0.915, delta=0.0,   gamma=0.0,   nu=4.659),\n",
    "        \"GARCH-M\":   dict(mu=0.019, lam=0.060, omega=0.000, alpha=0.042, beta=0.917, delta=0.0,   gamma=0.0,   nu=4.662),\n",
    "        \"GARCH-M-L\": dict(mu=-0.045,lam=0.122, omega=0.000, alpha=0.044, beta=0.920, delta=0.027, gamma=17.124,nu=4.903),\n",
    "    },\n",
    "    \"JNJ\": {\n",
    "        \"GARCH\":     dict(mu=0.067, lam=0.0,   omega=0.002, alpha=0.054, beta=0.904, delta=0.0,   gamma=0.0,   nu=9.941),\n",
    "        \"GARCH-M\":   dict(mu=0.058, lam=0.032, omega=0.000, alpha=0.025, beta=0.919, delta=0.0,   gamma=0.0,   nu=4.387),\n",
    "        \"GARCH-M-L\": dict(mu=0.033, lam=0.063, omega=0.003, alpha=0.026, beta=0.916, delta=0.017, gamma=1.029, nu=4.557),\n",
    "    },\n",
    "    \"MRK\": {\n",
    "        \"GARCH\":     dict(mu=0.078, lam=0.0,   omega=0.078, alpha=0.043, beta=0.832, delta=0.0,   gamma=0.0,   nu=4.763),\n",
    "        \"GARCH-M\":   dict(mu=0.077, lam=-0.015,omega=0.015, alpha=0.040, beta=0.904, delta=0.0,   gamma=0.0,   nu=4.502),\n",
    "        \"GARCH-M-L\": dict(mu=0.094, lam=0.065, omega=0.044, alpha=0.076, beta=0.867, delta=0.076, gamma=0.121, nu=9.977),\n",
    "    },\n",
    "}\n",
    "\n",
    "# 4) X-range (in percent) for news-impact curves (assignment example uses ~[-5,5])\n",
    "X_MIN, X_MAX, X_N = -5.0, 5.0, 501\n",
    "\n",
    "# ========================= MODEL FUNCTIONS =========================\n",
    "\n",
    "def news_impact_sigma2(x_grid, p):\n",
    "    \"\"\"\n",
    "    News-impact curve for model (1), holding sigma_{t-1}^2 = 1.\n",
    "    sigma_t^2 = omega + (alpha + delta * tanh(-gamma * x_{t-1}))\n",
    "                * ((x_{t-1} - mu - lam * sigma_{t-1}^2) / sigma_{t-1})^2\n",
    "                + beta * sigma_{t-1}^2\n",
    "    \"\"\"\n",
    "    mu    = float(p.get(\"mu\",    0.0) or 0.0)\n",
    "    lam   = float(p.get(\"lam\",   0.0) or 0.0)\n",
    "    omega = float(p.get(\"omega\", 0.0) or 0.0)\n",
    "    alpha = float(p.get(\"alpha\", 0.0) or 0.0)\n",
    "    beta  = float(p.get(\"beta\",  0.0) or 0.0)\n",
    "    delta = float(p.get(\"delta\", 0.0) or 0.0)\n",
    "    gamma = float(p.get(\"gamma\", 0.0) or 0.0)\n",
    "\n",
    "    sig2_prev = 1.0\n",
    "    sig_prev  = 1.0\n",
    "    inner = (x_grid - mu - lam*sig2_prev) / sig_prev\n",
    "    mult  = alpha + delta * np.tanh(-gamma * x_grid)\n",
    "    sig2  = omega + mult * (inner**2) + beta*sig2_prev\n",
    "    return sig2\n",
    "\n",
    "def filter_sigma2(x, p):\n",
    "    \"\"\"\n",
    "    Filter conditional variances sigma_t^2 over the full sample using model (1).\n",
    "    Per assignment: sigma_1^2 = population variance of first 50 returns (divide by 50, not 49).\n",
    "    x must be in percent units.\n",
    "    \"\"\"\n",
    "    mu    = float(p.get(\"mu\",    0.0) or 0.0)\n",
    "    lam   = float(p.get(\"lam\",   0.0) or 0.0)\n",
    "    omega = float(p.get(\"omega\", 0.0) or 0.0)\n",
    "    alpha = float(p.get(\"alpha\", 0.0) or 0.0)\n",
    "    beta  = float(p.get(\"beta\",  0.0) or 0.0)\n",
    "    delta = float(p.get(\"delta\", 0.0) or 0.0)\n",
    "    gamma = float(p.get(\"gamma\", 0.0) or 0.0)\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    T = len(x)\n",
    "    if T < 60:\n",
    "        raise ValueError(\"Not enough observations to set sigma_1^2 from first 50 returns.\")\n",
    "\n",
    "    # sigma_1^2: population variance of first 50 returns\n",
    "    x50 = x[:50]\n",
    "    sig2 = np.empty(T)\n",
    "    sig2[0] = np.mean((x50 - x50.mean())**2)\n",
    "    sig = np.sqrt(max(sig2[0], 1e-12))\n",
    "\n",
    "    for t in range(1, T):\n",
    "        inner = (x[t-1] - mu - lam*sig2[t-1]) / (sig if sig > 0 else 1e-12)\n",
    "        mult  = alpha + delta * np.tanh(-gamma * x[t-1])\n",
    "        sig2[t] = omega + mult * (inner**2) + beta * sig2[t-1]\n",
    "        sig = np.sqrt(max(sig2[t], 1e-12))\n",
    "    return sig2\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(RETURNS_CSV)\n",
    "df.columns = [c.lower() for c in df.columns]\n",
    "required = {\"date\", \"ticker\", \"ret\"}\n",
    "if not required.issubset(df.columns):\n",
    "    raise ValueError(f\"Returns CSV must contain columns: {required}\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"ticker\"] = df[\"ticker\"].str.upper()\n",
    "\n",
    "# Keep only the three stocks required by Q5 (rows in the panel)\n",
    "stocks = [\"PFE\", \"JNJ\", \"MRK\"]\n",
    "\n",
    "# Plot 3×2 panel\n",
    "x_grid = np.linspace(X_MIN, X_MAX, X_N)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10), constrained_layout=True)\n",
    "\n",
    "for i, s in enumerate(stocks):\n",
    "    sub = df[df[\"ticker\"] == s].sort_values(\"date\")\n",
    "    if sub.empty:\n",
    "        raise ValueError(f\"No rows found for ticker {s} in {RETURNS_CSV}.\")\n",
    "    \n",
    "    from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "# ---------- LEFT: news-impact curves ----------\n",
    "    axL = axes[i, 0]\n",
    "    \n",
    "    styles = {\n",
    "        \"GARCH\":     dict(color=\"#E68400\", linestyle=\"-\", lw=1.8),  # orange\n",
    "        \"GARCH-M\":   dict(color=\"#2ca02c\", linestyle=\"-\", lw=1.8),  # green\n",
    "        \"GARCH-M-L\": dict(color=\"#1f77b4\", linestyle=\"-\", lw=1.8),  # blue\n",
    "    }\n",
    "    \n",
    "    for model in [\"GARCH\", \"GARCH-M\", \"GARCH-M-L\"]:\n",
    "        p = PARAMS[s][model]\n",
    "        y = news_impact_sigma2(x_grid, p)\n",
    "        axL.plot(x_grid, y, label=model.replace(\"-\", \"–\"), **styles[model])\n",
    "    \n",
    "    axL.set_title(f\"News impact curve for {s}\", fontweight=\"bold\")\n",
    "    axL.set_xlabel(r\"$x_{t-1}$\", fontweight=\"bold\")\n",
    "    axL.set_ylabel(\"News impact\", rotation=90, labelpad=8, fontweight=\"bold\")\n",
    "    \n",
    "    # Fix X & Free Y + padding(0.2)\n",
    "    axL.set_xlim(-5.2, 5.2)\n",
    "    axL.relim(); axL.autoscale()\n",
    "    ymin, ymax = axL.get_ylim()\n",
    "    axL.set_ylim(ymin - 0.2, ymax + 0.2)\n",
    "    \n",
    "    axL.set_xticks(np.linspace(-5, 5, 5))\n",
    "    axL.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "    axL.yaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "    \n",
    "    axL.set_facecolor(\"#E5E5E5\")\n",
    "    axL.grid(True, which=\"major\", axis=\"both\", color=\"white\", linewidth=1.2)\n",
    "    axL.grid(True, which=\"minor\", axis=\"both\", color=\"white\", linewidth=0.6, alpha=0.7)\n",
    "    axL.tick_params(direction=\"out\", length=5, width=1)\n",
    "    \n",
    "    axL.legend(frameon=True, loc=\"upper right\")\n",
    "\n",
    "# ---------- RIGHT: filtered volatilities (GARCH-M-L) ----------\n",
    "    axR = axes[i, 1]\n",
    "    p_ml = PARAMS[s][\"GARCH-M-L\"]\n",
    "    \n",
    "    dates    = sub[\"date\"].values\n",
    "    rets_raw = sub[\"ret\"].values\n",
    "    rets_pct = rets_raw * 100.0 if np.nanmedian(np.abs(rets_raw)) < 2.0 else rets_raw.copy()\n",
    "    sig2     = filter_sigma2(rets_pct, p_ml)\n",
    "    \n",
    "    axR.set_facecolor(\"#E5E5E5\")\n",
    "    \n",
    "    # Returns: grey\n",
    "    axR.fill_between(dates, 0.0, rets_pct, color=\"#636363\", alpha=0.6, label=\"Returns (%)\", linewidth=0)\n",
    "    axR.plot(dates, rets_pct, color=\"#636363\", alpha=0.6, lw=0.8)\n",
    "    \n",
    "    # σ²: blue line\n",
    "    axR.plot(dates, sig2, lw=1.8, alpha=0.95, color=\"#1f77b4\", label=r\"GARCH–M–L ($\\sigma_t^2$)\")\n",
    "    \n",
    "    # cutoff \n",
    "    cutoff = pd.to_datetime(IN_SAMPLE_CUTOFF_DATE)\n",
    "    axR.axvline(cutoff, linestyle=\"--\", linewidth=1.2, color=\"0.2\")\n",
    "    \n",
    "    axR.set_title(f\"Filtered volatilities for {s}\", fontweight=\"bold\")\n",
    "    \n",
    "    # ylim\n",
    "    ylim = max(np.nanmax(np.abs(rets_pct)), np.nanmax(sig2)) * 1.10\n",
    "    axR.set_ylim(-ylim, ylim)\n",
    "    axR.yaxis.set_ticks_position(\"left\")\n",
    "    \n",
    "    # year: every 5 years\n",
    "    axR.xaxis.set_major_locator(mdates.YearLocator(base=5))\n",
    "    axR.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "    axR.xaxis.set_minor_locator(mdates.YearLocator())\n",
    "    \n",
    "    axR.grid(True, which=\"major\", color=\"white\", linewidth=1.2)\n",
    "    axR.grid(True, which=\"minor\", color=\"white\", linewidth=0.6, alpha=0.7)\n",
    "    \n",
    "    axR.legend(frameon=False, loc=\"upper right\")\n",
    "\n",
    "\n",
    "# fig.suptitle(\"Q5: News-impact curves and filtered volatilities\", y=1.02)\n",
    "\n",
    "# Save & show\n",
    "fig.savefig(\"fig_q5_panel.pdf\", bbox_inches=\"tight\")\n",
    "fig.savefig(\"fig_q5_panel.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: fig_q5_panel.pdf and fig_q5_panel.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Scale returns IN MEMORY (do NOT overwrite CSV on disk)\n",
    "df[\"RET\"] = df[\"RET\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_squared_path(ticker, model_type, target_date):\n",
    "\n",
    "    # data\n",
    "    df_date = df.loc[df['date'] <= target_date].sort_values('date')\n",
    "    ret_per_ticker = df_date[df_date['TICKER'] == ticker]['RET']\n",
    "    x = np.asarray(ret_per_ticker, dtype=float)\n",
    "    T = x.size\n",
    "\n",
    "    # initialize\n",
    "    sigma_sqrd = np.zeros(T)\n",
    "    sigma_sqrd[0] = np.average((x[:50] - np.average(x[:50]))**2)\n",
    "            \n",
    "    # parameters\n",
    "    final_params = par_results[ticker][model_type]\n",
    "    \n",
    "    if model_type == 'GARCH':\n",
    "        mu, omega, alpha, beta, nu = final_params\n",
    "        cond_mean = mu\n",
    "        for t in range(1, T):\n",
    "            resid_prev = (x[t-1] - cond_mean) / np.sqrt(sigma_sqrd[t-1])\n",
    "            sigma_sqrd[t] = omega + alpha * resid_prev**2 + beta * sigma_sqrd[t-1]\n",
    "    elif model_type == 'GARCH-M':\n",
    "        mu, lam, omega, alpha, beta, nu = final_params\n",
    "        for t in range(1, T):\n",
    "            cond_mean = mu + lam * sigma_sqrd[t-1]\n",
    "            resid_prev = (x[t-1] - cond_mean) / np.sqrt(sigma_sqrd[t-1])\n",
    "            sigma_sqrd[t] = omega + alpha * resid_prev**2 + beta * sigma_sqrd[t-1]\n",
    "    elif model_type == 'GARCH-M-L':\n",
    "        mu, lam, omega, alpha, delta, gamma, beta, nu = final_params\n",
    "        for t in range(1, T):\n",
    "            cond_mean = mu + lam * sigma_sqrd[t-1]\n",
    "            resid_prev = (x[t-1] - cond_mean) / np.sqrt(sigma_sqrd[t-1])\n",
    "            arch_coeff = alpha + delta * np.tanh(-gamma * x[t-1])\n",
    "            sigma_sqrd[t] = omega + arch_coeff * resid_prev**2 + beta * sigma_sqrd[t-1]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type specified.\")\n",
    "        \n",
    "\n",
    "    # return everything up to and including target date\n",
    "    return sigma_sqrd\n",
    "\n",
    "# Lists of tickers, model types, parameters and sigma_squared path\n",
    "\n",
    "tickers_to_fit = ['MRK', 'AAPL','PFE', 'JNJ' ]\n",
    "model_types = ['GARCH', 'GARCH-M', 'GARCH-M-L']\n",
    "date = pd.Timestamp('2021-01-04')\n",
    "\n",
    "sig_path_results = {}\n",
    "\n",
    "for ticker in tickers_to_fit:\n",
    "  print(\"=\" * 60)\n",
    "  print(f\"\\n Sigma squared path FOR TICKER: {ticker}\\n\")\n",
    "  print(\"=\" * 60)\n",
    "\n",
    "  sig_path_results[ticker] = {}\n",
    "  for model_type in model_types:\n",
    "      sig_path_results[ticker][model_type] = sigma_squared_path(ticker, model_type, date)\n",
    "      print(f\"\\n sigma squared on {date}: {sig_path_results[ticker][model_type][-1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the results\n",
    "print(sig_path_results)\n",
    "print(len(sig_path_results['AAPL']['GARCH']))\n",
    "print(sig_path_results['AAPL']['GARCH'][-1])\n",
    "print(df.loc[df['date'] ==date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_path(ticker, model_type, sigma_sqrd_t0, H=5, nsims=10, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    x0 = float(df.loc[(df['TICKER'] == ticker) & (df['date'] == date), 'RET'].iloc[0])\n",
    "\n",
    "    fp = par_results[ticker][model_type]\n",
    "    if model_type == 'GARCH':\n",
    "        mu, omega, alpha, beta, nu = fp\n",
    "        lam = 0.0; delta = 0.0; gamma = 0.0\n",
    "    elif model_type == 'GARCH-M':\n",
    "        mu, lam, omega, alpha, beta, nu = fp\n",
    "        delta = 0.0; gamma = 0.0\n",
    "    elif model_type == 'GARCH-M-L':\n",
    "        mu, lam, omega, alpha, delta, gamma, beta, nu = fp\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type specified.\")\n",
    "\n",
    "    x = np.empty((nsims, H+1), dtype=float)\n",
    "    x[:, 0] = x0\n",
    "    sigma_sqrd = np.empty((nsims, H+1), dtype=float)\n",
    "    sigma_sqrd[:, 0] = float(sigma_sqrd_t0)\n",
    "\n",
    "    eps = rng.standard_t(df=nu, size=(nsims, H))\n",
    "    tiny = 1e-12\n",
    "\n",
    "    for h in range(H):\n",
    "        sig = np.sqrt(np.maximum(sigma_sqrd[:, h], tiny))\n",
    "        mean_tm1 = mu + lam * sigma_sqrd[:, h]   \n",
    "\n",
    "        z_prev = (x[:, h] - mean_tm1) / np.maximum(sig, tiny)\n",
    "\n",
    "        if model_type == 'GARCH-M-L':\n",
    "            arch_coeff = alpha + delta * np.tanh(-gamma * x[:, h])\n",
    "        else:\n",
    "            arch_coeff = alpha\n",
    "\n",
    "        sigma_sqrd[:, h+1] = np.maximum(omega + arch_coeff*(z_prev**2) + beta*sigma_sqrd[:, h], tiny)\n",
    "\n",
    "        mean_next = mu + lam * sigma_sqrd[:, h+1]\n",
    "        x[:, h+1] = mean_next + np.sqrt(sigma_sqrd[:, h+1]) * eps[:, h]\n",
    "\n",
    "    gross   = 1.0 + x[:, 1:] / 100.0\n",
    "    cumprod = np.cumprod(gross, axis=1)\n",
    "\n",
    "    comp_1  = x[:, 1]\n",
    "    comp_5  = 100.0*(cumprod[:, 4]  - 1.0) if H >= 5  else None\n",
    "    comp_20 = 100.0*(cumprod[:, 19] - 1.0) if H >= 20 else None\n",
    "\n",
    "    return x, sigma_sqrd, comp_1, comp_5, comp_20\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['MRK','AAPL','PFE','JNJ']\n",
    "models  = ['GARCH','GARCH-M','GARCH-M-L']\n",
    "levels  = [0.01, 0.05, 0.10]\n",
    "\n",
    "rows = []\n",
    "for s in tickers:\n",
    "    for m in models:\n",
    "        sigma2_t0 = sig_path_results[s][m][-1]   # filtered variance on 2021-01-04\n",
    "        _, _, r1, r5, r20 = simulated_path(\n",
    "            s, m, sigma2_t0,\n",
    "            H=20, nsims=100000, seed=123  \n",
    "        )\n",
    "        rows.append({\n",
    "            \"Stock\": s, \"Model\": m,\n",
    "            \"VaR_1d_1%\":  float(np.quantile(r1,  0.01)),\n",
    "            \"VaR_1d_5%\":  float(np.quantile(r1,  0.05)),\n",
    "            \"VaR_1d_10%\": float(np.quantile(r1,  0.10)),\n",
    "            \"VaR_5d_1%\":  float(np.quantile(r5,  0.01)),\n",
    "            \"VaR_5d_5%\":  float(np.quantile(r5,  0.05)),\n",
    "            \"VaR_5d_10%\": float(np.quantile(r5,  0.10)),\n",
    "            \"VaR_20d_1%\": float(np.quantile(r20, 0.01)),\n",
    "            \"VaR_20d_5%\": float(np.quantile(r20, 0.05)),\n",
    "            \"VaR_20d_10%\":float(np.quantile(r20, 0.10)),\n",
    "        })\n",
    "\n",
    "var_table = pd.DataFrame(rows).set_index([\"Stock\",\"Model\"]).sort_index()\n",
    "var_table.round(2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
